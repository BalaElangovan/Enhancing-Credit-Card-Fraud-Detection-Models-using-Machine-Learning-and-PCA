{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cef5a1-62cc-411f-80f4-c5924e2e49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data = pd.read_csv('creditcard_2023.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info()\n",
    "\n",
    "# Check for missing values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Drop the 'id' column as it is not useful for the analysis\n",
    "data.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Plot the distribution of the 'Class' variable\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Class', data=data)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of the 'Amount' variable\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(data['Amount'], bins=50)\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Plot a heatmap of the correlations between variables\n",
    "plt.figure(figsize=(12,8))\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Scale the 'Amount' column to have a mean of 0 and standard deviation of 1\n",
    "scaler = StandardScaler()\n",
    "data['Amount'] = scaler.fit_transform(data[['Amount']])\n",
    "\n",
    "# Create new features based on 'user_id' if it exists in the dataset\n",
    "if 'user_id' in data.columns:\n",
    "    data['Transaction_Frequency'] = data.groupby('user_id')['Amount'].transform('count')\n",
    "else:\n",
    "    data['Transaction_Frequency'] = 1  # If 'user_id' does not exist, set default value\n",
    "\n",
    "if 'user_id' in data.columns:\n",
    "    data['Mean_Transaction_Amount'] = data.groupby('user_id')['Amount'].transform('mean')\n",
    "else:\n",
    "    data['Mean_Transaction_Amount'] = data['Amount']  # If 'user_id' does not exist, use 'Amount'\n",
    "\n",
    "# Create temporal features based on 'Time' if it exists in the dataset\n",
    "if 'Time' in data.columns:\n",
    "    data['Hour'] = (data['Time'] / 3600).astype(int) % 24\n",
    "    data['Time_Since_Last_Transaction'] = data.groupby('user_id')['Time'].diff().fillna(0)\n",
    "else:\n",
    "    data['Hour'] = 0  # If 'Time' does not exist, set default value\n",
    "    data['Time_Since_Last_Transaction'] = 0  # If 'Time' does not exist, set default value\n",
    "\n",
    "# Create merchant-related features if 'Merchant_ID' exists in the dataset\n",
    "if 'Merchant_ID' in data.columns:\n",
    "    data['Merchant_Transaction_Count'] = data.groupby('Merchant_ID')['Amount'].transform('count')\n",
    "else:\n",
    "    data['Merchant_Transaction_Count'] = 1  # If 'Merchant_ID' does not exist, set default value\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a ColumnTransformer for preprocessing the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), ['Amount', 'Transaction_Frequency', 'Mean_Transaction_Amount', 'Hour',\n",
    "                                     'Time_Since_Last_Transaction', 'Merchant_Transaction_Count'])],\n",
    "    remainder='passthrough'  # Keep all other columns as they are\n",
    ")\n",
    "\n",
    "# Define PCA for dimensionality reduction, retaining 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Define a pipeline for Logistic Regression\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', pca),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define a pipeline for Random Forest\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', pca),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define a pipeline for Neural Network\n",
    "neural_network_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', pca),\n",
    "    ('classifier', MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Store the pipelines in a dictionary\n",
    "pipelines = {\n",
    "    'Logistic Regression (PCA)': logistic_pipeline,\n",
    "    'Random Forest (PCA)': random_forest_pipeline,\n",
    "    'Neural Network (PCA)': neural_network_pipeline\n",
    "}\n",
    "\n",
    "# Dictionary to store the results of each model\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, pipeline in pipelines.items():\n",
    "    start_time = time.time()\n",
    "    pipeline.fit(X_train, y_train)  # Train the model\n",
    "    train_time = time.time() - start_time  # Calculate training time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions = pipeline.predict(X_test)  # Make predictions on the test set\n",
    "    predict_time = time.time() - start_time  # Calculate prediction time\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])  # Calculate AUC-ROC score\n",
    "    report = classification_report(y_test, predictions)  # Generate classification report\n",
    "    \n",
    "    results[name] = {\n",
    "        'classification_report': report,\n",
    "        'AUC-ROC': auc_roc,\n",
    "        'train_time': train_time,\n",
    "        'predict_time': predict_time\n",
    "    }\n",
    "\n",
    "# Plot the ROC curve for each model\n",
    "plt.figure()\n",
    "for name in results:\n",
    "    fpr, tpr, _ = roc_curve(y_test, pipelines[name].predict_proba(X_test)[:, 1])\n",
    "    plt.plot(fpr, tpr, label=f'{name} (area = {results[name][\"AUC-ROC\"]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot the diagonal line (random classifier)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix for each model\n",
    "for name in results:\n",
    "    cm = confusion_matrix(y_test, pipelines[name].predict(X_test))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.show()\n",
    "\n",
    "# Print the results for each model\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}\\n\"\n",
    "          f\"Classification Report:\\n{result['classification_report']}\\n\"\n",
    "          f\"AUC-ROC: {result['AUC-ROC']}\\n\"\n",
    "          f\"Training Time: {result['train_time']:.4f} seconds\\n\"\n",
    "          f\"Prediction Time: {result['predict_time']:.4f} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
